<!DOCTYPE html>
<html>
<title>Yang's Portfolio</title>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1">
<link rel="stylesheet" href="https://www.w3schools.com/w3css/4/w3.css">
<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
<style>
html,body,h1,h2,h3,h4,h5,h6 {font-family: "Roboto", sans-serif}
iframe {
    margin-left: auto;   /* Automatic margin from left */
    margin-right: auto; /* Automatic margin from right */
    display:block;
} 
img {
  display: block;
  margin-left: auto;
  margin-right: auto;
}

figure img {
    vertical-align: top;
}
figure figcaption {
    text-align: center;
}

    
</style>
<body class="w3-light-grey">

<!-- Page Container -->
<div class="w3-content w3-margin-top" style="max-width:1400px;">

  <!-- The Grid -->
  <div class="w3-row-padding">
  
    <!-- Left Column -->
    <div class="w3-third" , style="width:200px;">
    
      <div class="w3-white w3-text-grey w3-card-4">
        <div class="w3-display-container">
          <img src="https://s1.ax1x.com/2020/06/15/NpZGrV.jpg" style="width:100%" alt="Avatar">
          <div class="w3-display-bottomleft w3-container w3-text-white">
            <h2>Yang Liu </h2>
          </div>
        </div>
        <div class="w3-container">
          <p><i class="fa fa-briefcase fa-fw w3-margin-right w3-large w3-text-teal"></i>Researcher</p>
          <p><i class="fa fa-home fa-fw w3-margin-right w3-large w3-text-teal"></i>London, UK</p>
          <p>yangliuav@mail.com</p>
          <hr>

          <p class="w3-large"><b><i class="fa fa-asterisk fa-fw w3-margin-right w3-text-teal"></i>Keywords:</b></p>
          <p>audio-visual fusion</p>
          <p>multi-target tracking</p>
          <p>video generation</p>
          <p>machine Perception</p>
          <p>Bayesian statistics</p>
          <p>acoustic localization</p>
          <p>acoustic classification</p>
          <p>GAN and VAE</p>
          <br>

          <p class="w3-large"><b><i class="fa fa-asterisk fa-fw w3-margin-right w3-text-teal"></i>Professional Service:</b></p>
          <p>IET Single Processing</p>
          <p>IET Navigation</p>
          <p>IET Computer Vision</p>
          <p>ICASSP</p>
          <p>IEEE Transaction on Multi-media</p>
          <br>
   
          <br>
        </div>
      </div><br>
        
    

    <!-- End Left Column -->
    </div>

    <!-- Right Column -->
    <div class="w3-twothird" , style="width:1150px;">

      <div class="w3-container w3-card w3-white">
        <h2 class="w3-text-grey w3-padding-16"><i class="fa fa-certificate fa-fw w3-margin-right w3-xxlarge w3-text-teal"></i>Acoustic scene classification and audio-visual mutual generation</h2>
        <div class="w3-container">
          <h5 class="w3-opacity"><b>Microsoft</b></h5>
          <h6 class="w3-text-teal"><i class="fa fa-calendar fa-fw w3-margin-right"></i>09.2019 - current</h6>
            <div class="w3-container">
                <h5 class="w3-opacity"><b>Contribution:</b></h5>
                <p> 1. Design and collect a video scene dataset, called AV-10 (about 30TB).</p>
                <p> 2. Propose an acoustic scene classification network based on Sureface Duo. The accuracy is 7% higher than that of state-of-the-art tested in the unseen city </p>
                <p> 3. Implement the audio-visual cross-modal mutual generation on Keras and Snpe on Android phone. It can generate the audio sound from image and generate image from an acoustic recording. </p>
                <p> 4. Submit papers to ECCV and NIPS and a US. patent.</p>
            </div>
            <hr>
            <div class="w3-container">
                <h5 class="w3-opacity"><b>Resource:</b></h5>
                <figure>
                    <img src="https://s1.ax1x.com/2020/06/15/NpZzMq.png" style="width:80%" alt="Avatar" , class="center">
                    <figcaption>Fig 1. AV10 dataset</figcaption>
                </figure>
                <figure>
                    <img src="https://s1.ax1x.com/2020/06/15/NpeAJJ.png" style="width:40%" alt="Avatar" , class="center">
                    <figcaption>Fig 2. Pipeline of classification</figcaption>
                </figure>
                 <figure>
                    <img src="https://s1.ax1x.com/2020/06/15/NpeioF.png" style="width:60%" alt="Avatar" , class="center">
                    <figcaption>Fig 3. Pipeline of AVGAN</figcaption>
                </figure>
                 <figure>
                    <img src="https://s1.ax1x.com/2020/06/15/Npeki4.png" style="width:60%" alt="Avatar" , class="center">
                    <figcaption>Fig 4. Result of AVGAN</figcaption>
                </figure>
                 <figure>
                    <img src="https://s1.ax1x.com/2020/06/18/NmY5yF.png" style="width:60%" alt="Avatar" , class="center">
                    <figcaption>Fig 5. SVAE</figcaption>
                </figure>
                 <figure>
                    <img src="https://s1.ax1x.com/2020/06/15/NpeEW9.png" style="width:60%" alt="Avatar" , class="center">
                    <figcaption>Fig 6. Result of SVAE</figcaption>
                </figure>

                <iframe width="560" height="315" src="https://www.youtube.com/embed/bNYS3GD_dUc" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
                <p></p>
                <iframe width="560" height="315" src="https://www.youtube.com/embed/CVDxLFCmRjw" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
                <p></p>
                <iframe width="560" height="315" src="https://www.youtube.com/embed/Zb4r5iZuViY" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
            </div>
            <hr>
            <div class="w3-container">
                <h5 class="w3-opacity"><b>Paper:</b></h5>
                <p>  SVAE-GAN: Audio-Image Bidirectional Translation using Correlation Representations, Yang Liu, Eric Sommerlade, Alexandros Neophytou, Sunando Sengupta, Conference on Neural Information Processing Systems (NIPS), 2020. (Submitted).</p>
                <p>  Acoustic Scene Classification with ‘Imagined’ Images, Yang Liu, Eric Sommerlade, Alexandros Neophytou, Sunando Sengupta, European Conference on Computer Vision (ECCV), 2020. (Submitted). </p>
            </div>
        </div>
      </div>
        
      <div class="w3-container w3-card w3-white">
        <h2 class="w3-text-grey w3-padding-16"><i class="fa fa-certificate fa-fw w3-margin-right w3-xxlarge w3-text-teal"></i>Multi-speaker tracking with a camera and microphone arrays</h2>
        <div class="w3-container">
          <h5 class="w3-opacity"><b>University of Surrey and BBC</b></h5>
          <h6 class="w3-text-teal"><i class="fa fa-calendar fa-fw w3-margin-right"></i>10.2015 - 11/2019</h6>
            <div class="w3-container">
                <h5 class="w3-opacity"><b>Contribution:</b></h5>
                <p>  Work with BBC and propose a mutli-speaker tracking framework with a microphone array and a camera using DOA, MUSIC, faster R-CNN and YOLO network.</p>
                <p>The muli-sensor data are fused by sequential Monte Carlo, deep learning and Bayesian statistics implemented on Matlab, C++ and Python. </p>
                <p>Nominated for Best student paper in International Conference on Acoustics, Speech, and Signal Processing (ICASSP) 2019 </p>
            </div>
            <hr>
            <div class="w3-container">
                <h5 class="w3-opacity"><b>Resource:</b></h5>
                <figure>
                    <img src="https://www.s3a-spatialaudio.org/wp-content/uploads/2019/07/audioScenic_S3A_july2019.jpg" style="width:80%" alt="Avatar" , class="center">
                    <figcaption>Fig 7. S3A</figcaption>
                </figure>
            
                <iframe width="560" height="315" src="https://www.youtube.com/embed/9_ruZGtuBi8" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
                <p></p>
                <iframe width="560" height="315" src="https://www.youtube.com/embed/UerTViv6uYs" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
            </div>
            <hr>
            <div class="w3-container">
                <h5 class="w3-opacity"><b>Paper:</b></h5>
                <p>Labelled non-zero particle flow for Multi-speaker tracking, Yang Liu, Wenwu Wang, IEEE Transactions on Signal processing (Submitted).</p>
                <p> Intensity Particle Flows for Sequential Monte Carlo Implementation of Probability Hypothesis Density Filter, Yang Liu, Wenwu Wang, IEEE Transactions on Signal processing (Submitted).</p>
                <p> Audio-visual Zero Diffusion Particle Flow SMC-PHD Filter for Multi-speaker Tracking, Yang Liu, Volkan Kilic, Jian Guan, Wenwu Wang, IEEE Transactions on Multimedia, August 2019 </p>
                <p> Labelled Non-zero Particle flow for SMC-PHD filtering, Yang Liu, Qinghua Hu, Yuexian Zou, Wenwu Wang, International Conference on Acoustics, Speech, and Signal Processing, 2019.</p>
                <p> Intensity Particle Flow SMC-PHD Filter For Audio Speaker Tracking, Yang Liu, Wenwu Wang, Volkan Kılıc, LOCATA challenge workshop, 2018. </p>
                <p> Audio-visual SMC-PHD Filter with Non Zero Diffusion Particle Flow, Yang Liu, Wenwu Wang, Volkan Kılıc, International Conference on Acoustics, Speech, and Signal Processing, 2018. </p>
                <p> Particle flow for sequential Monte Carlo implementation of probability hypothesis density, Yang Liu, Wenwu Wang, Yuxin Zhao, International Conference on Acoustics, Speech, and Signal Processing, 2017. </p>
                <p> Particle Flow SMC-PHD Filter for Audio-Visual Multi-speaker Tracking, Yang Liu, Wenwu Wang, onathon Chambers, Adrian Hilton, International Conference on Latent Variable Analysis and Signal Separation, 2017 </p>
            </div>
        </div>
      </div>

    <!-- End Right Column -->
    </div>
    
  <!-- End Grid -->
  </div>
  
  <!-- End Page Container -->
</div>

<footer class="w3-container w3-teal w3-center w3-margin-top">
  <p>Find me on social media.</p>
  <i class="fa fa-facebook-official w3-hover-opacity"></i>
  <i class="fa fa-instagram w3-hover-opacity"></i>
  <i class="fa fa-snapchat w3-hover-opacity"></i>
  <i class="fa fa-pinterest-p w3-hover-opacity"></i>
  <i class="fa fa-twitter w3-hover-opacity"></i>
  <i class="fa fa-linkedin w3-hover-opacity"></i>
</footer>

</body>
</html>
